The annual list of the most common causes of death in the
United States, compiled by the Centers for Disease Control and
Prevention (CDC), informs public awareness and national
research priorities each year. The list is created using death
certificates filled out by physicians, funeral directors, medical
examiners, and coroners. However, a major limitation of the
death certificate is that it relies on assigning an International
Classification of Disease (ICD) code to the cause of death.1 As
a result, causes of death not associated with an ICD code, such
as human and system factors, are not captured. The science of
safety has matured to describe how communication breakdowns,
diagnostic errors, poor judgment, and inadequate skill can
directly result in patient harm and death. We analyzed the
scientific literature on medical error to identify its contribution
to US deaths in relation to causes listed by the CDC.2
Death from medical care itself
Medical error has been defined as an unintended act (either of
omission or commission) or one that does not achieve its
intended outcome,3
the failure of a planned action to be
completed as intended (an error of execution), the use of a wrong
plan to achieve an aim (an error of planning),4
or a deviation
from the process of care that may or may not cause harm to the
patient.5 Patient harm from medical error can occur at the
individual or system level. The taxonomy of errors is expanding
to better categorize preventable factors and events.6 We focus
on preventable lethal events to highlight the scale of potential
for improvement.
The role of error can be complex. While many errors are
non-consequential, an error can end the life of someone with a
long life expectancy or accelerate an imminent death. The case
in the box shows how error can contribute to death. Moving
away from a requirement that only reasons for death with an
ICD code can be used on death certificates could better inform
healthcare research and awareness priorities.
How big is the problem?
The most commonly cited estimate of annual deaths from
medical error in the US—a 1999 Institute of Medicine (IOM)
report7—is limited and outdated. The report describes an
incidence of 44 000-98 000 deaths annually.7 This conclusion
was not based on primary research conducted by the institute
but on the 1984 Harvard Medical Practice Study and the 1992
Utah and Colorado Study.8 9 But as early as 1993, Leape, a chief
investigator in the 1984 Harvard study, published an article
arguing that the study’s estimate was too low, contending that
78% rather than 51% of the 180 000 iatrogenic deaths were
preventable (some argue that all iatrogenic deaths are
preventable).10 This higher incidence (about 140 400 deaths due
to error) has been supported by subsequent studies which suggest
that the 1999 IOM report underestimates the magnitude of the
problem. A 2004 report of inpatient deaths associated with the
Agency for Healthcare Quality and Research Patient Safety
Indicators in the Medicare population estimated that 575 000
deaths were caused by medical error between 2000 and 2002,
which is about 195 000 deaths a year (table 1⇓).11 Similarly, the
US Department of Health and Human Services Office of the
Inspector General examining the health records of hospital
inpatients in 2008, reported 180 000 deaths due to medical error
a year among Medicare beneficiaries alone.12 Using similar
methods, Classen et al described a rate of 1.13%.13 If this rate
is applied to all registered US hospital admissions in 201315 it
translates to over 400 000 deaths a year, more than four times
the IOM estimate.
Similarly, Landrigan et al reported that 0.6% of hospital
admissions in a group of North Carolina hospitals over six years
(2002-07) resulted in lethal adverse events and conservatively
estimated that 63% were due to medical errors.14 Extrapolated
nationally, this would translate into 134 581 inpatient deaths a
year from poor inpatient care. Of note, none of the studies
captured deaths outside inpatient care—those resulting from
errors in care at home or in nursing homes and in outpatient
care such as ambulatory surgery centers.A literature review by James estimated preventable adverse
events using a weighted analysis and described an incidence
range of 210 000-400 000 deaths a year associated with medical
errors among hospital patients.16 We calculated a mean rate of
death from medical error of 251 454 a year using the studies
reported since the 1999 IOM report and extrapolating to the
total number of US hospital admissions in 2013. We believe
this understates the true incidence of death due to medical error
because the studies cited rely on errors extractable in
documented health records and include only inpatient deaths.
Although the assumptions made in extrapolating study data to
the broader US population may limit the accuracy of our figure,
the absence of national data highlights the need for systematic
measurement of the problem. Comparing our estimate to CDC
rankings suggests that medical error is the third most common
cause of death in the US (fig 1⇓).2
Better data
Human error is inevitable. Although we cannot eliminate human
error, we can better measure the problem to design safer systems
mitigating its frequency, visibility, and consequences. Strategies
to reduce death from medical care should include three steps:
making errors more visible when they occur so their effects can
be intercepted; having remedies at hand to rescue patients 17;
and making errors less frequent by following principles that
take human limitations into account (fig 2⇓). This multitier
approach necessitates guidance from reliable data.
Currently, deaths caused by errors are unmeasured and
discussions about prevention occur in limited and confidential
forums, such as a hospital’s internal root cause analysis
committee or a department’s morbidity and mortality conference.
These forums review only a fraction of detected adverse events
and the lessons learnt are not disseminated beyond the institution
or department.
There are several possible strategies to estimate accurate national
statistics for death due to medical error. Instead of simply
requiring cause of death, death certificates could contain an
extra field asking whether a preventable complication stemming
from the patient’s medical care contributed to the death. An
early experience asking physicians to comment on the potential
preventability of inpatient deaths immediately after they
occurred resulted in an 89% response rate.18 Another strategy
would be for hospitals to carry out a rapid and efficient
independent investigation into deaths to determine the potential
contribution of error. A root cause analysis approach would
enable local learning while using medicolegal protections to
maintain anonymity. Standardized data collection and reporting
processes are needed to build up an accurate national picture of
the problem. Measuring the consequences of medical care on
patient outcomes is an important prerequisite to creating a
culture of learning from our mistakes, thereby advancing the
science of safety and moving us closer towards the Institute of
Medicine’s goal of creating learning health systems.19
Health priorities
We have estimated that medical error is the third biggest cause
of death in the US and therefore requires greater attention.
Medical error leading to patient death is under-recognized in
many other countries, including the UK and Canada.20 21
According to WHO, 117 countries code their mortality statistics
using the ICD system as the primary indicator of health status.22
The ICD-10 coding system has limited ability to capture most
types of medical error. At best, there are only a few codes where
the role of error can be inferred, such as the code for
anticoagulation causing adverse effects and the code for
overdose events. When a medical error results in death, both
the physiological cause of the death and the related problem
with delivery of care should be captured.
To achieve more reliable healthcare systems, the science of
improving safety should benefit from sharing data nationally
and internationally, in the same way as clinicians share research
and innovation about coronary artery disease, melanoma, and
influenza. Sound scientific methods, beginning with an
assessment of the problem, are critical to approaching any health
threat to patients. The problem of medical error should not be
exempt from this scientific approach. More appropriate
recognition of the role of medical error in patient death could
heighten awareness and guide both collaborations and capital
investments in research and prevention.
Contributors and sources: MM is the developer of the operating room
checklist, the precursor to the WHO surgery checklist. He is a surgical
oncologist at Johns Hopkins and author of Unaccountable, a book about
transparency in healthcare. MD is the Rodda patient safety research
fellow at Johns Hopkins and is focused on health services research.
This article arose from discussions about the paucity of funding available
to support quality and safety research relative to other causes of death.
Competing interests: We have read and understood BMJ policy on
declaration of interests and declare that we have no competing interests.
Provenance and peer review: Not commissioned; externally peer
reviewed.
In 1916, the year after the final formulation of the field
equations of general relativity, Albert Einstein predicted
the existence of gravitational waves. He found that
the linearized weak-field equations had wave solutions:
transverse waves of spatial strain that travel at the speed of
light, generated by time variations of the mass quadrupole
moment of the source [1,2]. Einstein understood that
gravitational-wave amplitudes would be remarkably
small; moreover, until the Chapel Hill conference in
1957 there was significant debate about the physical
reality of gravitational waves [3].
Also in 1916, Schwarzschild published a solution for the
field equations [4] that was later understood to describe a
black hole [5,6], and in 1963 Kerr generalized the solution
to rotating black holes [7]. Starting in the 1970s theoretical
work led to the understanding of black hole quasinormal
modes [8–10], and in the 1990s higher-order postNewtonian calculations [11] preceded extensive analytical
studies of relativistic two-body dynamics [12,13]. These
advances, together with numerical relativity breakthroughs
in the past decade [14–16], have enabled modeling of
binary black hole mergers and accurate predictions of
their gravitational waveforms. While numerous black hole
candidates have now been identified through electromagnetic observations [17–19], black hole mergers have not
previously been observed.
The discovery of the binary pulsar system PSR B1913þ16
by Hulse and Taylor [20] and subsequent observations of
its energy loss by Taylor and Weisberg [21] demonstrated
the existence of gravitational waves. This discovery,
along with emerging astrophysical understanding [22],
led to the recognition that direct observations of the
amplitude and phase of gravitational waves would enable
studies of additional relativistic systems and provide new
tests of general relativity, especially in the dynamic
strong-field regime.
Experiments to detect gravitational waves began with
Weber and his resonant mass detectors in the 1960s [23],
followed by an international network of cryogenic resonant detectors [24]. Interferometric detectors were first
suggested in the early 1960s [25] and the 1970s [26]. A
study of the noise and performance of such detectors [27],
and further concepts to improve them [28], led to
proposals for long-baseline broadband laser interferometers with the potential for significantly increased sensitivity [29–32]. By the early 2000s, a set of initial detectors
was completed, including TAMA 300 in Japan, GEO 600
in Germany, the Laser Interferometer Gravitational-Wave
Observatory (LIGO) in the United States, and Virgo in
Italy. Combinations of these detectors made joint observations from 2002 through 2011, setting upper limits on a
variety of gravitational-wave sources while evolving into
a global network. In 2015, Advanced LIGO became the
first of a significantly more sensitive network of advanced
detectors to begin observations [33–36].
A century after the fundamental predictions of Einstein
and Schwarzschild, we report the first direct detection of
gravitational waves and the first direct observation of a
binary black hole system merging to form a single black
hole. Our observations provide unique access to the properties of space-time in the strong-field, high-velocity
regime and confirm predictions of general relativity for the
nonlinear dynamics of highly disturbed black holes.
II. OBSERVATION
On September 14, 2015 at 09:50:45 UTC, the LIGO
Hanford, WA, and Livingston, LA, observatories detected
the coincident signal GW150914 shown in Fig. 1. The initial
detection was made by low-latency searches for generic
gravitational-wave transients [41] and was reported within
three minutes of data acquisition [43]. Subsequently,
matched-filter analyses that use relativistic models of compact binary waveforms [44] recovered GW150914 as the
most significant event from each detector for the observations reported here. Occurring within the 10-ms intersite
The gravitational-wave event GW150914 observed by the LIGO Hanford (H1, left column panels) and Livingston (L1, right
column panels) detectors. Times are shown relative to September 14, 2015 at 09:50:45 UTC. For visualization, all time series are filtered
with a 35–350 Hz bandpass filter to suppress large fluctuations outside the detectors’ most sensitive frequency band, and band-reject
filters to remove the strong instrumental spectral lines seen in the Fig. 3 spectra. Top row, left: H1 strain. Top row, right: L1 strain.
GW150914 arrived first at L1 and 6.9þ0.5 −0.4 ms later at H1; for a visual comparison, the H1 data are also shown, shifted in time by this
amount and inverted (to account for the detectors’ relative orientations). Second row: Gravitational-wave strain projected onto each
detector in the 35–350 Hz band. Solid lines show a numerical relativity waveform for a system with parameters consistent with those
recovered from GW150914 [37,38] confirmed to 99.9% by an independent calculation based on [15]. Shaded areas show 90% credible
regions for two independent waveform reconstructions. One (dark gray) models the signal using binary black hole template waveforms
[39]. The other (light gray) does not use an astrophysical model, but instead calculates the strain signal as a linear combination of
sine-Gaussian wavelets [40,41]. These reconstructions have a 94% overlap, as shown in [39]. Third row: Residuals after subtracting the
filtered numerical relativity waveform from the filtered detector time series. Bottom row:A time-frequency representation [42] of the
strain data, showing the signal frequency increasing over time. propagation time, the events have a combined signal-tonoise ratio (SNR) of 24 [45].
Only the LIGO detectors were observing at the time of
GW150914. The Virgo detector was being upgraded,
and GEO 600, though not sufficiently sensitive to detect
this event, was operating but not in observational
mode. With only two detectors the source position is
primarily determined by the relative arrival time and
localized to an area of approximately 600 deg2 (90%
credible region) [39,46].
The basic features of GW150914 point to it being
produced by the coalescence of two black holes—i.e.,
their orbital inspiral and merger, and subsequent final black
hole ringdown. Over 0.2 s, the signal increases in frequency
and amplitude in about 8 cycles from 35 to 150 Hz, where
the amplitude reaches a maximum. The most plausible
explanation for this evolution is the inspiral of two orbiting
masses, m1 and m2, due to gravitational-wave emission. At
the lower frequencies, such evolution is characterized by
the chirp mass
where f and f_ are the observed frequency and its time
derivative and G and c are the gravitational constant and
speed of light. Estimating f and f_ from the data in Fig. 1,
we obtain a chirp mass of M ≃ 30M⊙, implying that the
total mass M ¼ m1 þ m2 is ≳70M⊙ in the detector frame.
This bounds the sum of the Schwarzschild radii of the
binary components to 2GM=c2 ≳ 210 km. To reach an
orbital frequency of 75 Hz (half the gravitational-wave
frequency) the objects must have been very close and very
compact; equal Newtonian point masses orbiting at this
frequency would be only ≃350 km apart. A pair of
neutron stars, while compact, would not have the required
mass, while a black hole neutron star binary with the
deduced chirp mass would have a very large total mass,
and would thus merge at much lower frequency. This
leaves black holes as the only known objects compact
enough to reach an orbital frequency of 75 Hz without
contact. Furthermore, the decay of the waveform after it
peaks is consistent with the damped oscillations of a black
hole relaxing to a final stationary Kerr configuration.
Below, we present a general-relativistic analysis of
GW150914; Fig. 2 shows the calculated waveform using
the resulting source parameters.
III. DETECTORS
Gravitational-wave astronomy exploits multiple, widely
separated detectors to distinguish gravitational waves from
local instrumental and environmental noise, to provide
source sky localization, and to measure wave polarizations.
The LIGO sites each operate a single Advanced LIGO
detector [33], a modified Michelson interferometer (see
Fig. 3) that measures gravitational-wave strain as a difference in length of its orthogonal arms. Each arm is formed
by two mirrors, acting as test masses, separated by
Lx ¼ Ly ¼ L ¼ 4 km. A passing gravitational wave effectively alters the arm lengths such that the measured
difference is ΔLðtÞ ¼ δLx − δLy ¼ hðtÞL, where h is the
gravitational-wave strain amplitude projected onto the
detector. This differential length variation alters the phase
difference between the two light fields returning to the
beam splitter, transmitting an optical signal proportional to
the gravitational-wave strain to the output photodetector.
To achieve sufficient sensitivity to measure gravitational
waves, the detectors include several enhancements to the
basic Michelson interferometer. First, each arm contains a
resonant optical cavity, formed by its two test mass mirrors,
that multiplies the effect of a gravitational wave on the light
phase by a factor of 300 [48]. Second, a partially transmissive power-recycling mirror at the input provides additional resonant buildup of the laser light in the interferometer
as a whole [49,50]: 20 W of laser input is increased to 700 W
incident on the beam splitter, which is further increased to
100 kW circulating in each arm cavity. Third, a partially
transmissive signal-recycling mirror at the output optimizes the gravitational-wave signal extraction by broadening the
bandwidth of the arm cavities [51,52]. The interferometer
is illuminated with a 1064-nm wavelength Nd:YAG laser,
stabilized in amplitude, frequency, and beam geometry
[53,54]. The gravitational-wave signal is extracted at the
output port using a homodyne readout [55].
These interferometry techniques are designed to maximize the conversion of strain to optical signal, thereby
minimizing the impact of photon shot noise (the principal
noise at high frequencies). High strain sensitivity also
requires that the test masses have low displacement noise,
which is achieved by isolating them from seismic noise (low
frequencies) and designing them to have low thermal noise
(intermediate frequencies). Each test mass is suspended as
the final stage of a quadruple-pendulum system [56],
supported by an active seismic isolation platform [57].
These systems collectively provide more than 10 orders
of magnitude of isolation from ground motion for frequencies above 10 Hz. Thermal noise is minimized by using
low-mechanical-loss materials in the test masses and their
suspensions: the test masses are 40-kg fused silica substrates
with low-loss dielectric optical coatings [58,59], and are
suspended with fused silica fibers from the stage above [60].
To minimize additional noise sources, all components
other than the laser source are mounted on vibration
isolation stages in ultrahigh vacuum. To reduce optical
phase fluctuations caused by Rayleigh scattering, the
pressure in the 1.2-m diameter tubes containing the armcavity beams is maintained below 1 μPa.
Servo controls are used to hold the arm cavities on
resonance [61] and maintain proper alignment of the optical
components [62]. The detector output is calibrated in strain
by measuring its response to test mass motion induced by
photon pressure from a modulated calibration laser beam
[63]. The calibration is established to an uncertainty (1σ) of
less than 10% in amplitude and 10 degrees in phase, and is
continuously monitored with calibration laser excitations at
selected frequencies. Two alternative methods are used to
validate the absolute calibration, one referenced to the main
laser wavelength and the other to a radio-frequency oscillator Additionally, the detector response to gravitational
waves is tested by injecting simulated waveforms with the
calibration laser.
To monitor environmental disturbances and their influence on the detectors, each observatory site is equipped
with an array of sensors: seismometers, accelerometers,
microphones, magnetometers, radio receivers, weather
sensors, ac-power line monitors, and a cosmic-ray detector
[65]. Another ∼105 channels record the interferometer’s
operating point and the state of the control systems. Data
collection is synchronized to Global Positioning System
(GPS) time to better than 10 μs [66]. Timing accuracy is
verified with an atomic clock and a secondary GPS receiver
at each observatory site.
In their most sensitive band, 100–300 Hz, the current
LIGO detectors are 3 to 5 times more sensitive to strain than
initial LIGO [67]; at lower frequencies, the improvement is
even greater, with more than ten times better sensitivity
below 60 Hz. Because the detectors respond proportionally
to gravitational-wave amplitude, at low redshift the volume
of space to which they are sensitive increases as the cube
of strain sensitivity. For binary black holes with masses
similar to GW150914, the space-time volume surveyed by
the observations reported here surpasses previous observations by an order of magnitude [68].
IV. DETECTOR VALIDATION
Both detectors were in steady state operation for several
hours around GW150914. All performance measures, in
particular their average sensitivity and transient noise
behavior, were typical of the full analysis period [69,70].
Exhaustive investigations of instrumental and environmental disturbances were performed, giving no evidence to
suggest that GW150914 could be an instrumental artifact
[69]. The detectors’ susceptibility to environmental disturbances was quantified by measuring their response to specially generated magnetic, radio-frequency, acoustic, and
vibration excitations. These tests indicated that any external
disturbance large enough to have caused the observed signal
would have been clearly recorded by the array of environmental sensors. None of the environmental sensors recorded
any disturbances that evolved in time and frequency like
GW150914, and all environmental fluctuations during the
second that contained GW150914 were too small to account
for more than 6% of its strain amplitude. Special care was
taken to search for long-range correlated disturbances that
might produce nearly simultaneous signals at the two sites.
No significant disturbances were found.
The detector strain data exhibit non-Gaussian noise
transients that arise from a variety of instrumental mechanisms. Many have distinct signatures, visible in auxiliary
data channels that are not sensitive to gravitational waves;
such instrumental transients are removed from our analyses
[69]. Any instrumental transients that remain in the data
are accounted for in the estimated detector backgrounds
described below. There is no evidence for instrumental
transients that are temporally correlated between the two
detectors.
V. SEARCHES
We present the analysis of 16 days of coincident
observations between the two LIGO detectors from
September 12 to October 20, 2015. This is a subset of
the data from Advanced LIGO’s first observational period
that ended on January 12, 2016.
GW150914 is confidently detected by two different
types of searches. One aims to recover signals from the
coalescence of compact objects, using optimal matched
filtering with waveforms predicted by general relativity.
The other search targets a broad range of generic transient
signals, with minimal assumptions about waveforms. These
searches use independent methods, and their response to
detector noise consists of different, uncorrelated, events.
However, strong signals from binary black hole mergers are
expected to be detected by both searches.
Each search identifies candidate events that are detected
at both observatories consistent with the intersite propagation time. Events are assigned a detection-statistic value
that ranks their likelihood of being a gravitational-wave
signal. The significance of a candidate event is determined
by the search background—the rate at which detector noise
produces events with a detection-statistic value equal to or
higher than the candidate event. Estimating this background is challenging for two reasons: the detector noise
is nonstationary and non-Gaussian, so its properties must
be empirically determined; and it is not possible to shield
the detector from gravitational waves to directly measure a
signal-free background. The specific procedure used to
estimate the background is slightly different for the two
searches, but both use a time-shift technique: the time
stamps of one detector’s data are artificially shifted by an
offset that is large compared to the intersite propagation
time, and a new set of events is produced based on this
time-shifted data set. For instrumental noise that is uncorrelated between detectors this is an effective way to
estimate the background. In this process a gravitationalwave signal in one detector may coincide with time-shifted
noise transients in the other detector, thereby contributing
to the background estimate. This leads to an overestimate of
the noise background and therefore to a more conservative
assessment of the significance of candidate events.
The characteristics of non-Gaussian noise vary between
different time-frequency regions. This means that the search
backgrounds are not uniform across the space of signals
being searched. To maximize sensitivity and provide a better
estimate of event significance, the searches sort both their
background estimates and their event candidates into different classes according to their time-frequency morphology.
The significance of a candidate event is measured against the
background of its class. To account for having searched
PRL 116, 061102 (2016) PHYSICAL REVIEW LETTERS week ending
12 FEBRUARY 2016
061102-5
multiple classes, this significance is decreased by a trials
factor equal to the number of classes [71].
A. Generic transient search
Designed to operate without a specific waveform model,
this search identifies coincident excess power in timefrequency representations of the detector strain data
[43,72], for signal frequencies up to 1 kHz and durations
up to a few seconds.
The search reconstructs signal waveforms consistent
with a common gravitational-wave signal in both detectors
using a multidetector maximum likelihood method. Each
event is ranked according to the detection statistic
ηc ¼ 
2Ec=ð1 þ En=EcÞ p , where Ec is the dimensionless
coherent signal energy obtained by cross-correlating the
two reconstructed waveforms, and En is the dimensionless
residual noise energy after the reconstructed signal is
subtracted from the data. The statistic ηc thus quantifies
the SNR of the event and the consistency of the data
between the two detectors.
Based on their time-frequency morphology, the events
are divided into three mutually exclusive search classes, as
described in [41]: events with time-frequency morphology
of known populations of noise transients (class C1), events
with frequency that increases with time (class C3), and all
remaining events (class C2).
Detected with ηc ¼ 20.0, GW150914 is the strongest
event of the entire search. Consistent with its coalescence
signal signature, it is found in the search class C3 of events
with increasing time-frequency evolution. Measured on a
background equivalent to over 67 400 years of data and
including a trials factor of 3 to account for the search
classes, its false alarm rate is lower than 1 in 22 500 years.
This corresponds to a probability < 2 × 10−6 of observing
one or more noise events as strong as GW150914 during
the analysis time, equivalent to 4.6σ. The left panel of
Fig. 4 shows the C3 class results and background.
The selection criteria that define the search class C3
reduce the background by introducing a constraint on the
signal morphology. In order to illustrate the significance of
GW150914 against a background of events with arbitrary
shapes, we also show the results of a search that uses the
same set of events as the one described above but without
this constraint. Specifically, we use only two search classes:
the C1 class and the union of C2 and C3 classes (C2 þ C3).
In this two-class search the GW150914 event is found in
the C2 þ C3 class. The left panel of Fig. 4 shows the
C2 þ C3 class results and background. In the background
of this class there are four events with ηc ≥ 32.1, yielding a
false alarm rate for GW150914 of 1 in 8 400 years. This
corresponds to a false alarm probability of 5 × 10−6
equivalent to 4.4σ For robustness and validation, we also use other generic
transient search algorithms [41]. A different search [73] and
a parameter estimation follow-up [74] detected GW150914
with consistent significance and signal parameters.
B. Binary coalescence search
This search targets gravitational-wave emission from
binary systems with individual masses from 1 to 99M⊙,
total mass less than 100M⊙, and dimensionless spins up to
0.99 [44]. To model systems with total mass larger than
4M⊙, we use the effective-one-body formalism [75], which
combines results from the post-Newtonian approach
[11,76] with results from black hole perturbation theory
and numerical relativity. The waveform model [77,78]
assumes that the spins of the merging objects are aligned
with the orbital angular momentum, but the resulting
templates can, nonetheless, effectively recover systems
with misaligned spins in the parameter region of
GW150914 [44]. Approximately 250 000 template waveforms are used to cover this parameter space.
The search calculates the matched-filter signal-to-noise
ratio ρðtÞ for each template in each detector and identifies
maxima of ρðtÞ with respect to the time of arrival of the signal
[79–81]. For each maximum we calculate a chi-squared
statistic χ2
r to test whether the data in several different
frequency bands are consistent with the matching template
[82]. Values of χ2
r near unity indicate that the signal is
consistent with a coalescence. If χ2
r is greater than unity, ρðtÞ
is reweighted as ρˆ ¼ ρ=f½1 þ ðχ2
r Þ3=2g1=6 [83,84]. The final
step enforces coincidence between detectors by selecting
event pairs that occur within a 15-ms window and come from
the same template. The 15-ms window is determined by the
10-ms intersite propagation time plus 5 ms for uncertainty in
arrival time of weak signals. We rank coincident events based
on the quadrature sum ρˆ c of the ρˆ from both detectors [45].
To produce background data for this search the SNR
maxima of one detector are time shifted and a new set of
coincident events is computed. Repeating this procedure
∼107 times produces a noise background analysis time
equivalent to 608 000 years.
To account for the search background noise varying across
the target signal space, candidate and background events are
divided into three search classes based on template length.
The right panel of Fig. 4 shows the background for the
search class of GW150914. The GW150914 detectionstatistic value of ρˆ c ¼ 23.6 is larger than any background
event, so only an upper bound can be placed on its false
alarm rate. Across the three search classes this bound is 1 in
203 000 years. This translates to a false alarm probability
< 2 × 10−7, corresponding to 5.1σ.
A second, independent matched-filter analysis that uses a
different method for estimating the significance of its
events [85,86], also detected GW150914 with identical
signal parameters and consistent significance.
When an event is confidently identified as a real
gravitational-wave signal, as for GW150914, the background used to determine the significance of other events is
reestimated without the contribution of this event. This is
the background distribution shown as a purple line in the
right panel of Fig. 4. Based on this, the second most
significant event has a false alarm rate of 1 per 2.3 years and
corresponding Poissonian false alarm probability of 0.02.
Waveform analysis of this event indicates that if it is
astrophysical in origin it is also a binary black hole
merger [44].
VI. SOURCE DISCUSSION
The matched-filter search is optimized for detecting
signals, but it provides only approximate estimates of
the source parameters. To refine them we use general
relativity-based models [77,78,87,88], some of which
include spin precession, and for each model perform a
coherent Bayesian analysis to derive posterior distributions
of the source parameters [89]. The initial and final masses,
final spin, distance, and redshift of the source are shown in
Table I. The spin of the primary black hole is constrained
to be < 0.7 (90% credible interval) indicating it is not
maximally spinning, while the spin of the secondary is only
weakly constrained. These source parameters are discussed
in detail in [39]. The parameter uncertainties include
statistical errors and systematic errors from averaging the
results of different waveform models.
Using the fits to numerical simulations of binary black
hole mergers in [92,93], we provide estimates of the mass
and spin of the final black hole, the total energy radiated
in gravitational waves, and the peak gravitational-wave
luminosity [39]. The estimated total energy radiated in
gravitational waves is 3.0þ0.5 −0.5M⊙c2. The system reached a
peak gravitational-wave luminosity of 3.6þ0.5 −0.4 × 1056 erg=s,
equivalent to 200þ30
−20M⊙c2=s.
Several analyses have been performed to determine
whether or not GW150914 is consistent with a binary black hole system in general relativity [94]. A first
consistency check involves the mass and spin of the final
black hole. In general relativity, the end product of a black
hole binary coalescence is a Kerr black hole, which is fully
described by its mass and spin. For quasicircular inspirals,
these are predicted uniquely by Einstein’s equations as a
function of the masses and spins of the two progenitor
black holes. Using fitting formulas calibrated to numerical
relativity simulations [92], we verified that the remnant
mass and spin deduced from the early stage of the
coalescence and those inferred independently from the late
stage are consistent with each other, with no evidence for
disagreement from general relativity.
Within the post-Newtonian formalism, the phase of the
gravitational waveform during the inspiral can be expressed
as a power series in f1=3. The coefficients of this expansion
can be computed in general relativity. Thus, we can test for
consistency with general relativity [95,96] by allowing the
coefficients to deviate from the nominal values, and seeing
if the resulting waveform is consistent with the data. In this
second check [94] we place constraints on these deviations,
finding no evidence for violations of general relativity.
Finally, assuming a modified dispersion relation for
gravitational waves [97], our observations constrain the
Compton wavelength of the graviton to be λg > 1013 km,
which could be interpreted as a bound on the graviton mass
mg < 1.2 × 10−22 eV=c2. This improves on Solar System
and binary pulsar bounds [98,99] by factors of a few and a
thousand, respectively, but does not improve on the modeldependent bounds derived from the dynamics of Galaxy
clusters [100] and weak lensing observations [101]. In
summary, all three tests are consistent with the predictions
of general relativity in the strong-field regime of gravity.
GW150914 demonstrates the existence of stellar-mass
black holes more massive than ≃25M⊙, and establishes that
binary black holes can form in nature and merge within a
Hubble time. Binary black holes have been predicted to form
both in isolated binaries [102–104] and in dense environments by dynamical interactions [105–107]. The formation
of such massive black holes from stellar evolution requires
weak massive-star winds, which are possible in stellar
environments with metallicity lower than ≃1=2 the solar
value [108,109]. Further astrophysical implications of this
binary black hole discovery are discussed in [110].
These observational results constrain the rate of stellarmass binary black hole mergers in the local universe. Using
several different models of the underlying binary black hole
mass distribution, we obtain rate estimates ranging from
2–400 Gpc−3 yr−1 in the comoving frame [111–113]. This
is consistent with a broad range of rate predictions as
reviewed in [114], with only the lowest event rates being
excluded.
Binary black hole systems at larger distances contribute
to a stochastic background of gravitational waves from the
superposition of unresolved systems. Predictions for such a
background are presented in [115]. If the signal from such a
population were detected, it would provide information
about the evolution of such binary systems over the history
of the universe.
VII. OUTLOOK
Further details about these results and associated data
releases are available at [116]. Analysis results for the
entire first observational period will be reported in future
publications. Efforts are under way to enhance significantly
the global gravitational-wave detector network [117].
These include further commissioning of the Advanced
LIGO detectors to reach design sensitivity, which will
allow detection of binaries like GW150914 with 3 times
higher SNR. Additionally, Advanced Virgo, KAGRA, and
a possible third LIGO detector in India [118] will extend
the network and significantly improve the position
reconstruction and parameter estimation of sources.
VIII. CONCLUSION
The LIGO detectors have observed gravitational waves
from the merger of two stellar-mass black holes. The
detected waveform matches the predictions of general
relativity for the inspiral and merger of a pair of black
holes and the ringdown of the resulting single black hole.
These observations demonstrate the existence of binary
stellar-mass black hole systems. This is the first direct
detection of gravitational waves and the first observation of
a binary black hole merger.
ACKNOWLEDGMENTS
The authors gratefully acknowledge the support of
the United States National Science Foundation (NSF) for
the construction and operation of the LIGO Laboratory
and Advanced LIGO as well as the Science and
Technology Facilities Council (STFC) of the United
Kingdom, the Max-Planck Society (MPS), and the State
of Niedersachsen, Germany, for support of the construction
of Advanced LIGO and construction and operation of the
GEO 600 detector. Additional support for Advanced LIGO
was provided by the Australian Research Council. The
authors gratefully acknowledge the Italian Istituto
Nazionale di Fisica Nucleare (INFN), the French Centre
National de la Recherche Scientifique (CNRS), and the
Foundation for Fundamental Research on Matter supported
by the Netherlands Organisation for Scientific Research,
for the construction and operation of the Virgo detector, and
for the creation and support of the EGO consortium. The
authors also gratefully acknowledge research support from
these agencies as well as by the Council of Scientific and
Industrial Research of India, Department of Science and
PRL 116, 061102 (2016) PHYSICAL REVIEW LETTERS week ending
12 FEBRUARY 2016
061102-8
Technology, India, Science & Engineering Research Board
(SERB), India, Ministry of Human Resource Development,
India, the Spanish Ministerio de Economía y
Competitividad, the Conselleria d’Economia i
Competitivitat and Conselleria d’Educació, Cultura i
Universitats of the Govern de les Illes Balears, the
National Science Centre of Poland, the European
Commission, the Royal Society, the Scottish Funding
Council, the Scottish Universities Physics Alliance, the
Hungarian Scientific Research Fund (OTKA), the Lyon
Institute of Origins (LIO), the National Research
Foundation of Korea, Industry Canada and the Province
of Ontario through the Ministry of Economic Development
and Innovation, the Natural Sciences and Engineering
Research Council of Canada, Canadian Institute for
Advanced Research, the Brazilian Ministry of Science,
Technology, and Innovation, Russian Foundation for Basic
Research, the Leverhulme Trust, the Research Corporation,
Ministry of Science and Technology (MOST), Taiwan, and
the Kavli Foundation. The authors gratefully acknowledge
the support of the NSF, STFC, MPS, INFN, CNRS and the
State of Niedersachsen, Germany, for provision of computational resources. This article has been assigned the
document numbers LIGO-P150914 and VIR-0015A-16.